---
title: "RCML-2014-conference"
author: "Oner, Indiogine et alii"
date: "October 22, 2014"
output: html_document
---
Initial settings, libraries and cleanup.
```{r initial, message=FALSE, warning=FALSE}
options(width=120)
rm(list=ls())
library(xlsx)
library(psych)
library(pmr)
setwd("~/Code/RCML/")
```

# Research Question 1
Import raw scores of algebra misconceptions
```{r load_data}
#temp.1 <- read.xlsx("Fall-2013-KATE-post-help.xlsx",sheetName="misconception",stringsAsFactors=FALSE,colIndex=c(1,(3:7)))
temp <- read.xlsx("Fall2013_data.xlsx", sheetName="misconception", stringsAsFactors=FALSE, colIndex=c(1,3:22), endRow=33)
my.data <- temp[-c(3,22,23),]
rm(temp)
```

```{r table_misconception}
Percent       <- (my.data$percent_1 + my.data$percent_2 + my.data$percent_3 )  / 15
Proportion    <- (my.data$proportion_1 + my.data$proportion_2 + my.data$proportion_3) / 15
X.values      <- my.data$Xvalues / 2
Coefficients  <- my.data$Coefficients / 2
ExprEq        <- my.data$ExprEq / 2
misconception <- data.frame(SRN = my.data$SRN,
                            Proportion, 
                            Percent, 
                            X.values,
                            Slope.Int = Coefficients,
                            Expr.Eq   = ExprEq)
misconception
```

Now we rank the misconceptions.
```{r}
misconception <- data.frame(misconception,
                            Proportion.rank = NA,
                            Percent.rank = NA,
                            X.values.rank = NA,
                            SlopeInt.rank = NA,
                            ExprEq.rank = NA)
```

```{r}
for (i in 1:nrow(misconception))
  { rank(misconception[i, 2:6], ties.method="max") -> misconception[i,7:11] }

print(misconception)
```
A high rank means a high score for helping the student to resolve the misconception.

Analysis of the rankings of the misconceptions using the R library "pmr". See http://www.biomedcentral.com/1471-2288/13/65
```{r}
my.ranks <- misconception[, c(7:11)]
my.ranks.agg <- rankagg(my.ranks)
destat(my.ranks.agg)
```
We can see that the PST did best in the "unequal intervals for the independent variable" misconception and worst with the "linear equation slope and intercept".  Thus, in decreasing order of comprehension we have (1) Unequal x-values, (2) percentages, (3) proportions, (4) expression versus equation, and (5) linear equation slope and intercept.

Now we test for uniformity of the five mean ranks we use a chi-square test. The following expression based on the rank means follows a chi-square distribution:

(12N/(k(k+1))) times the summation of the square of the difference between the rank mean and (k+1)/2

k: number of items, in our case 5
N: number of observations, in our case 29

```{r}
de1 <- destat(my.ranks.agg)
k.subtract <- (5+1)/2
my.mean <- rep(k.subtract, 5)
Nk.multiply <- (12*29)/(5*(5+1))
my.chi <- Nk.multiply*sum((de1$mean.rank - my.mean)^2)
print(my.chi)
dchisq(my.chi, 4)
```
Based on the extremely low probability value of the chi-square statistic we conclude that the rank means are different, and thus there is a difference in capability of the PSTs in helping the students with misconceptions. 


# Research Question 2
What is the relationship between the capability of helping the students with misconceptions and problem solving knowledge of the PSTs?

We answer this research question by calculating the correlation between KATE questions that test for algebra content knowledge (correct/incorrect scores, binary) and the misconception questions from the equity challenge problems (scored 0,1,2,3,4,5, ordered categorical) and the KATE misconceptions questions (scored 0,1,2, ordered categorical).  In this case we do not aggregate the three percentages and proportions scores for the three subquestions.

We need to remove columns that have all same values because they have 0 variance.  These columns are KATE Q6, Q7, and Q8.
```{r prepare_ordinal_data}
equity.misc <- my.data[,2:7]
equity.misc
#equity.misc.temp <- lapply(equity.misc, factor, levels=0:5)
#equity.misc <- data.frame(equity.misc.temp)

KATE.misc <- my.data[,8:10]
KATE.misc
#KATE.misc.temp <- lapply(KATE.misc, factor, levels=0:2)
#KATE.misc <- data.frame(KATE.misc.temp)

KATE.CK <- my.data[,c(11,12,13,14,15,19,20,21)]
KATE.CK
#KATE.CK.temp <- lapply(KATE.CK, factor, levels=0:1)
#KATE.CK <- data.frame(KATE.CK.temp)

big.table <- cbind(equity.misc, KATE.misc, KATE.CK)
```

Run correlations of ordinal categorical data.
```{r}
my.model <- mixed.cor(big.table, method="spearman")
my.model
```

Different procedure
```{r use_psych}
corr.test(big.table, method="spearman") -> my.result
print(my.result, short=FALSE)
```

# Research question 3

Load the spreadsheet with MTEBI and misconceptions scores.
```{r load_MTEBI}
rq3.data <- read.xlsx("RQ3dataset.xlsx", header=TRUE,
                      sheetName="Sheet1", as.data.frame=TRUE,
                      stringsAsFactors=FALSE, 
                      colIndex=c(2:22,24:44,46:50), 
                      endRow=29)
rq3.data
```

Split the data into MTEBI pre-survey, MTEBI post-survey, and misconception tables.
MTEBI PMTE: Q2, 3, 5, 6, 8, 11, 15, 16, 17, 18, 19, 20, 21
MTEBI MTOE: Q1, 4, 7, 12, 13, 14


```{r split_data}
MTEBI.pre     <- data.frame(rq3.data[,1:21])
MTEBI.post    <- data.frame(rq3.data[22:42])
misconception <- data.frame(rq3.data[43:47])
PMTE.pre      <- data.frame(rq3.data[,c(2,3,5,6,8,11,15)])
MTOE.pre      <- data.frame(rq3.data[,c(1,4,7,12,13,14)])
PMTE.post     <- data.frame(rq3.data[,c(23,24,26,27,29,32,36)])
MTOE.post     <- data.frame(rq3.data[,c(22,25,28,33,34,35)])
```

We run correlation test between MTEBI components and misconceptions.
```{r rq3_correlations}

```

